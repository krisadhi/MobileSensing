# Deep-Learning Based Tracking for Mobile Sensing

_Group Collaborators: Krisha Adhikari (kadhikari@umass.edu), Aadarsha Rai (aadarsharai@umass.edu_

**Motivation**  

Tracking is important for many different uses with mobile embedded systems. They provide a way to map out the environment in a virtual reality, 
and can even be used in real life applications with robotics. The deep learning model that is used to track the data gathered from 
mobile embedded systems can greatly affect the performance. Improving this performance results in better virtual reality environments and experience.  

**Design goals**

- Developing deep learning tracking algorithm for two mobile systems
- Will include implementing TartanVO, a visual odometry model and benchmarking it with multiple datasets

**Deliverables**  

- Implement and understand an end-to-end learning approach for tracking - TartanVO  
- Benchmark TartanVO on two datasets (KITTI and EuRoC)  
- Analyze performance on the datasets  

**hw/sw requirements**  

- Need to know how to code in Python
- Need a laptop/PC with a CUDA enabled GPU

**Team members responsibilities**  

Krisha: Setup, Writing  
Aadi: Software, Research  

**Project timeline**  

TartanVO Understanding: October 10th  
Setup Environment: October 30th
Implement TartanVO on Dataset 1: November 15th
Implement TartanVO on Dataset 2: November 30th
Analyze TartanVO and finalize: December 5th

**References**  

_TartanVO: https://arxiv.org/pdf/2011.00359.pdf_  
_Code: https://github.com/castacks/tartanvo_  
_Datasets: KITTI (https://www.cvlibs.net/datasets/kitti/eval_odometry.php), EuRoC (https://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets)_ 


